{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mixing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55k8J-h8Uz5K"
      },
      "source": [
        "## Install and import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKUheZwrAjys",
        "outputId": "d977191b-b728-4201-8b08-d65cf6440f5c"
      },
      "source": [
        "# !pip install torch==1.4.0\n",
        "# !pip install transformers==2.11.0\n",
        "# !pip install attrdict==2.0.1\n",
        "!pip install datasets transformers attrdict"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting datasets\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/df/4f/8ef6e4df6e92fc02da620ccfac249112619e5c21273a836958160d6e96fb/datasets-1.6.1-py3-none-any.whl (220kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225kB 4.4MB/s \n",
            "\u001b[?25hCollecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.1MB 7.1MB/s \n",
            "\u001b[?25hCollecting attrdict\n",
            "  Downloading https://files.pythonhosted.org/packages/ef/97/28fe7e68bc7adfce67d4339756e85e9fcf3c6fd7f0c0781695352b70472c/attrdict-2.0.1-py2.py3-none-any.whl\n",
            "Collecting fsspec\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/91/2ef649137816850fa4f4c97c6f2eabb1a79bf0aa2c8ed198e387e373455e/fsspec-2021.4.0-py3-none-any.whl (108kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 112kB 13.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.41.1)\n",
            "Collecting huggingface-hub<0.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from datasets) (3.10.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.11.1)\n",
            "Collecting xxhash\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/4f/0a862cad26aa2ed7a7cd87178cbbfa824fc1383e472d63596a0d018374e7/xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 245kB 17.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (20.9)\n",
            "Requirement already satisfied: pyarrow>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.3MB 21.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 901kB 50.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from attrdict) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.4.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: fsspec, huggingface-hub, xxhash, datasets, tokenizers, sacremoses, transformers, attrdict\n",
            "Successfully installed attrdict-2.0.1 datasets-1.6.1 fsspec-2021.4.0 huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.5.1 xxhash-2.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuJGaXYXANoX"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertPreTrainedModel, BertModel\n",
        "from transformers import BertTokenizer\n",
        "from typing import Union, Optional\n",
        "\n",
        "import numpy as np\n",
        "from transformers.pipelines import ArgumentHandler\n",
        "from transformers import (\n",
        "    Pipeline,\n",
        "    PreTrainedTokenizer,\n",
        "    ModelCard\n",
        ")\n",
        "from pprint import pprint\n",
        "import os\n",
        "import google.colab as colab\n",
        "import pandas as pd\n",
        "import json\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuuJNk-oQc2P",
        "outputId": "44d90295-edf5-4082-85a5-fcd1667ee5d4"
      },
      "source": [
        "def mount_google_drive():\n",
        "\t'''\n",
        "\t# Functionality\n",
        "\t\tMount google drive. Since colab does not save files, we want to make it easier to directly access files in google drive.\n",
        "\t# Arguments\n",
        "\t\tNothing\n",
        "\t# Returns\n",
        "\t\tdrive_root: the working directory mounted\n",
        "\t'''\n",
        "\tmount_directory = \"/content/gdrive\"\n",
        "\tdrive = colab.drive\n",
        "\tdrive.mount(mount_directory, force_remount=True)\n",
        "\tdrive_root = mount_directory + \"/\" + list(filter(lambda x: x[0] != '.', os.listdir(mount_directory)))[0]\n",
        "\treturn drive_root\n",
        "\n",
        "ROOT_DIR =  mount_google_drive() + \"/goemotion/\"\n",
        "CHECKPOINT_ROOT = ROOT_DIR+ \"goemotion-ckpt/original/checkpoint-10000\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5KIaRKJU75a"
      },
      "source": [
        "## Model Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hERifRwsCgvD"
      },
      "source": [
        "class BertForMultiLabelClassification(BertPreTrainedModel):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.num_labels = config.num_labels\n",
        "\n",
        "        self.bert = BertModel(config)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.classifier = nn.Linear(config.hidden_size, self.config.num_labels)\n",
        "        self.loss_fct = nn.BCEWithLogitsLoss()\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(\n",
        "            self,\n",
        "            input_ids=None,\n",
        "            attention_mask=None,\n",
        "            token_type_ids=None,\n",
        "            position_ids=None,\n",
        "            head_mask=None,\n",
        "            inputs_embeds=None,\n",
        "            labels=None,\n",
        "    ):\n",
        "        outputs = self.bert(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "        )\n",
        "        pooled_output = outputs[1]\n",
        "\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "\n",
        "        outputs = (logits,) + outputs[2:]  # add hidden states and attention if they are here\n",
        "\n",
        "        if labels is not None:\n",
        "            loss = self.loss_fct(logits, labels)\n",
        "            outputs = (loss,) + outputs\n",
        "\n",
        "        return outputs  # (loss), logits, (hidden_states), (attentions)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7BwhC2r_DB4"
      },
      "source": [
        "# Retrieval helpers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXP_HKrm_Edg"
      },
      "source": [
        "def generate_candidates(test_sents):\n",
        "  # simplest case: just flip the sentences\n",
        "  return test_sents[::-1]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMbWJfoseqti"
      },
      "source": [
        "# Inference On Testset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-yX-nBYLY1w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02480a64-1b83-4642-a85d-26e70023d9b6"
      },
      "source": [
        "device = 0\n",
        "threshold = 0.3\n",
        "tokenizer = BertTokenizer.from_pretrained(CHECKPOINT_ROOT)\n",
        "model = BertForMultiLabelClassification.from_pretrained(CHECKPOINT_ROOT)\n",
        "model = model.to(device)\n",
        "\n",
        "# goemotions = MultiLabelPipeline(\n",
        "#     model=model,\n",
        "#     tokenizer=tokenizer,\n",
        "#     threshold=0.3\n",
        "# )\n",
        "\n",
        "def goemotions(texts):\n",
        "  torch.cuda.set_device(device)\n",
        "  # 1. Tokenizer pass for both test inputs and candidate inputs\n",
        "  inputs = tokenizer(\n",
        "            texts,\n",
        "            add_special_tokens=True,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "            truncation=False,\n",
        "        )\n",
        "  with torch.no_grad():\n",
        "    # 2. Model Forward pass\n",
        "    inputs = {name: tensor.to(device) for name, tensor in inputs.items()}\n",
        "    # outputs = model(**inputs)[0].cpu()\n",
        "    outputs = model(input_ids=inputs[\"input_ids\"],\n",
        "                    attention_mask=inputs[\"attention_mask\"],\n",
        "                    token_type_ids=inputs[\"token_type_ids\"])[0].cpu()\n",
        "    # 3. Inference output post-processing\n",
        "    scores = 1 / (1 + np.exp(-outputs))  # Sigmoid\n",
        "    results = []\n",
        "    for item in scores:\n",
        "        labels = []\n",
        "        scores = []\n",
        "        for idx, s in enumerate(item):\n",
        "            if s > threshold:\n",
        "                labels.append(model.config.id2label[idx])\n",
        "                scores.append(float(s))\n",
        "        results.append({\"labels\": labels, \"scores\": scores})\n",
        "    return results\n",
        "\n",
        "texts = [\n",
        "    \"Hey that's a thought! Maybe we need [NAME] to be the celebrity vaccine endorsement!\",\n",
        "    \"itâ€™s happened before?! love my hometown of beautiful new ken ðŸ˜‚ðŸ˜‚\",\n",
        "    \"I love you, brother.\",\n",
        "    \"Troll, bro. They know they're saying stupid shit. The motherfucker does nothing but stink up libertarian subs talking shit\",\n",
        "]\n",
        "\n",
        "pprint(goemotions(texts))\n",
        "\n",
        "# Output\n",
        "#  [{'labels': ['neutral'], 'scores': [0.9750906]},\n",
        "#  {'labels': ['curiosity', 'love'], 'scores': [0.9694574, 0.9227462]},\n",
        "#  {'labels': ['love'], 'scores': [0.993483]},\n",
        "#  {'labels': ['anger'], 'scores': [0.99225825]}]\n",
        "\n",
        "# [{'labels': ['optimism'], 'scores': [0.3206218481063843]},\n",
        "#  {'labels': ['curiosity', 'love'],\n",
        "#   'scores': [0.4122002422809601, 0.8766248226165771]},\n",
        "#  {'labels': ['love'], 'scores': [0.9667580723762512]},\n",
        "#  {'labels': ['anger'], 'scores': [0.9185698628425598]}]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'input_ids': tensor([[  101,  4403,  1115,   112,   188,   170,  1354,   106,  2389,  1195,\n",
            "          1444,     1,  1106,  1129,  1103, 10948, 20034, 22843,   106,   102,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0],\n",
            "        [  101,  1122,   787,   188,  2171,  1196,   136,   106,  1567,  1139,\n",
            "          9694,  1104,  2712,  1207,   180,  1424,   100,   102,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0],\n",
            "        [  101,   146,  1567,  1128,   117,  1711,   119,   102,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0],\n",
            "        [  101,   157, 10747,   117,  9304,  1186,   119,  1220,  1221,  1152,\n",
            "           112,  1231,  2157,  4736,  4170,   119,  1109,  1534, 14703,  8638,\n",
            "          1674,  1720,  1133,   188,  6105,  1377,  1146,   181, 24851, 24279,\n",
            "          4841,  1116,  2520,  4170,   102]], device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n",
            "[{'labels': ['optimism'], 'scores': [0.32062193751335144]},\n",
            " {'labels': ['curiosity', 'love'],\n",
            "  'scores': [0.4122002422809601, 0.8766248226165771]},\n",
            " {'labels': ['love'], 'scores': [0.9667580723762512]},\n",
            " {'labels': ['anger'], 'scores': [0.9185698628425598]}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSlGJyN2bWOF",
        "outputId": "81a9bd0c-7dec-4aef-b099-191df46f2082"
      },
      "source": [
        "inputs = tokenizer(\n",
        "            texts,\n",
        "            add_special_tokens=True,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "            truncation=False,\n",
        "        )\n",
        "\n",
        "print(inputs.keys())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAG9X4FCVKYa"
      },
      "source": [
        "## Load Test set and true labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFdDWpSWEgcY"
      },
      "source": [
        "# Load labels and build dicts\n",
        "with open(ROOT_DIR + \"data/original/labels.txt\", \"r\") as f:\n",
        "  labels = f.read().splitlines()\n",
        "label2index = {v: k for k, v in enumerate(labels)}\n",
        "index2label = {k: v for k, v in enumerate(labels)}\n",
        "\n",
        "\n",
        "# Load test set, get test sents and ground truths\n",
        "df = pd.read_csv(ROOT_DIR + \"data/original/test.tsv\", sep='\\t', header=None, names=[\"sentence\", \"label\", \"encoding\"])\n",
        "sentences = df.sentence.tolist()\n",
        "ground_truths = []\n",
        "for x in df.label.tolist():\n",
        "  single_idxs = x.split(\",\")\n",
        "  single_labels = []\n",
        "  for label in single_idxs:\n",
        "    single_labels.append(index2label[int(label)])\n",
        "  ground_truths.append(single_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGV_2xe-KHZu"
      },
      "source": [
        "# raw_predictions = []\n",
        "# batch_size = 81\n",
        "# num_batches = len(sentences) / batch_size\n",
        "\n",
        "# i = 0\n",
        "# while i < len(sentences):\n",
        "#   raw_predictions += goemotions(sentences[i: i + batch_size])\n",
        "#   i = i + batch_size\n",
        "\n",
        "# with open(ROOT_DIR + \"data/original/predictions_epoch4.json\", 'w') as f:\n",
        "#   json.dump(raw_predictions, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifKtNZvPPXzV"
      },
      "source": [
        "with open(ROOT_DIR + \"data/original/predictions_epoch4.json\", 'r') as f:\n",
        "  raw_predictions = json.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuxQMe7sRweS"
      },
      "source": [
        "predictions = [x[\"labels\"] for x in raw_predictions]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23NtvvUZRxT-",
        "outputId": "fd3e07be-2be0-4438-dec2-451e1c031f81"
      },
      "source": [
        "len(ground_truths) == len(predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJVNXZ17m0X-",
        "outputId": "d98e449c-f1b3-450b-b2ae-1019f956306c"
      },
      "source": [
        "num_em = 0\n",
        "for i, (pred, truth) in enumerate(zip(predictions, ground_truths)):\n",
        "  if pred != truth and \"grief\" in truth:\n",
        "    num_em += 1\n",
        "    print(sentences[i])\n",
        "    print(pred)\n",
        "    print(truth)\n",
        "    print(\"------------------\")\n",
        "# print(num_em / len(predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[NAME] death is just so..... senseless. Why? WHY??? The based gods have forsaken us\n",
            "[]\n",
            "['grief']\n",
            "------------------\n",
            "Rip the guy from psych\n",
            "['neutral']\n",
            "['grief']\n",
            "------------------\n",
            "The only death that made me feel any emotion. And it wasnâ€™t even the death itself.\n",
            "['neutral']\n",
            "['grief', 'sadness']\n",
            "------------------\n",
            "My condolences.\n",
            "['sadness']\n",
            "['grief', 'sadness']\n",
            "------------------\n",
            "Oh my gosh. This woman who died also had a son who died. Holy tragedy\n",
            "['sadness', 'surprise']\n",
            "['grief', 'sadness', 'surprise']\n",
            "------------------\n",
            "You'll miss a begging old man asking for a spare coin. RIP\n",
            "['neutral']\n",
            "['grief', 'sadness']\n",
            "------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlGpWLT0oy2Q",
        "outputId": "93e33b9b-625b-49f9-8ae0-4288f3cdc6e8"
      },
      "source": [
        "num_em = 0\n",
        "for i, (pred, truth) in enumerate(zip(predictions, ground_truths)):\n",
        "  if pred != truth and \"pride\" in truth:\n",
        "    num_em += 1\n",
        "    print(sentences[i])\n",
        "    print(pred)\n",
        "    print(truth)\n",
        "    print(\"------------------\")\n",
        "# print(num_em / len(predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I only eat cronuts cuz I'm sophisticated!\n",
            "['approval']\n",
            "['pride']\n",
            "------------------\n",
            "This internet stranger is also super proud of you! Way to go!!!\n",
            "['admiration', 'excitement']\n",
            "['admiration', 'pride']\n",
            "------------------\n",
            "Thatâ€™s better:-) now go get em tiger\n",
            "['approval', 'neutral']\n",
            "['approval', 'optimism', 'pride']\n",
            "------------------\n",
            "My jersey has the great number 10 on it!!\n",
            "['admiration']\n",
            "['pride']\n",
            "------------------\n",
            "And I taught my room was dirty and that I was not taking care of my self. Good job op\n",
            "['admiration']\n",
            "['admiration', 'pride']\n",
            "------------------\n",
            "I am proud of you random internet stranger, you peopled good today.\n",
            "['admiration']\n",
            "['admiration', 'pride']\n",
            "------------------\n",
            "That's nothing, before BSE we did horrible things with bone meal animal feed. Cannibal cows.\n",
            "['disapproval']\n",
            "['pride']\n",
            "------------------\n",
            "Yep. I did this in uni, got mad respect for holding my \"booze\". \n",
            "['admiration', 'approval']\n",
            "['pride']\n",
            "------------------\n",
            "Youâ€™re doing so good! Weâ€™re all so proud!\n",
            "['admiration']\n",
            "['admiration', 'pride']\n",
            "------------------\n",
            "I have no shame in saying I still have my blanket from when I was a child. And a favorite [NAME] plushie.\n",
            "['joy', 'neutral']\n",
            "['pride']\n",
            "------------------\n",
            "We have reached the stage where below 2 million is good. There truly is no bottom to this pit.\n",
            "['approval']\n",
            "['admiration', 'pride']\n",
            "------------------\n",
            "I did! Never moving back, I love my life in the \"big smoke\".\n",
            "['love']\n",
            "['joy', 'pride']\n",
            "------------------\n",
            "Boy what an accomplishment, so proud!\n",
            "['admiration']\n",
            "['pride']\n",
            "------------------\n",
            "Thats the high life of empowerment.\n",
            "['neutral']\n",
            "['pride', 'neutral']\n",
            "------------------\n",
            "I am proud to be racist No one in real life will know this\n",
            "['excitement']\n",
            "['pride']\n",
            "------------------\n",
            "iâ€™m so proud of you!! good job dude!! :)\n",
            "['admiration']\n",
            "['admiration', 'pride']\n",
            "------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diUvI-fzo50k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c60f24d1-9b2b-473a-c3ec-3723523008df"
      },
      "source": [
        "num_em = 0\n",
        "for i, (pred, truth) in enumerate(zip(predictions, ground_truths)):\n",
        "  if pred != truth and \"relief\" in truth:\n",
        "    num_em += 1\n",
        "    print(sentences[i])\n",
        "    print(pred)\n",
        "    print(truth)\n",
        "    print(\"------------------\")\n",
        "# print(num_em / len(predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Resetting a dislocated knee hurts like hell but it feels a lot better immediately after.\n",
            "['caring']\n",
            "['relief']\n",
            "------------------\n",
            "Praise the [NAME] for REALITY! WOOF!!!!!\n",
            "['admiration']\n",
            "['relief']\n",
            "------------------\n",
            "I'm glad you have someone to help you out! Perhaps over time you'll find it easier.\n",
            "['caring', 'joy']\n",
            "['joy', 'relief']\n",
            "------------------\n",
            "Iâ€™ve exposed on social media. It made me feel better so I donâ€™t care what anyway has to say about it.\n",
            "['approval', 'realization']\n",
            "['relief']\n",
            "------------------\n",
            "at least it wasnâ€™t the evil [NAME].\n",
            "['neutral']\n",
            "['relief']\n",
            "------------------\n",
            "Yay, coming out is hard, you're lucky that they didnt avoid you for the next month, I'm happy for you\n",
            "['joy']\n",
            "['caring', 'joy', 'relief']\n",
            "------------------\n",
            "I'm glad it only sprayed soda when his thumb went into the can, and not blood everywhere.\n",
            "['joy']\n",
            "['relief']\n",
            "------------------\n",
            "Glad I'm not the only one\n",
            "['joy']\n",
            "['joy', 'relief']\n",
            "------------------\n",
            "This is really helpful to point out!!\n",
            "['approval', 'gratitude']\n",
            "['relief']\n",
            "------------------\n",
            "I have little to no anxiety and it really helps me when i have to take a test.\n",
            "[]\n",
            "['relief']\n",
            "------------------\n",
            "Oh thatâ€™s actually seriously a relief, how do you know that though?\n",
            "['approval', 'curiosity']\n",
            "['curiosity', 'relief']\n",
            "------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4axG-t-vMH4"
      },
      "source": [
        "def convert_onehot(inputs):\n",
        "  final_arr = np.zeros((len(inputs), len(label2index.keys())))\n",
        "  for i, labels in enumerate(inputs):\n",
        "    for label in labels:\n",
        "      final_arr[i, label2index[label]] = 1\n",
        "  return final_arr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGfbAVRLwuMg"
      },
      "source": [
        "onehot_truths = convert_onehot(ground_truths)\n",
        "onehot_preds = convert_onehot(predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjadPCC3yH1Y"
      },
      "source": [
        "multilabel_confmat = multilabel_confusion_matrix(onehot_truths, onehot_preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVBysHlIy89_"
      },
      "source": [
        "cls_report = {}\n",
        "for i in range(multilabel_confmat.shape[0]):\n",
        "  cls_report[index2label[i]] = {}\n",
        "  cls_report[index2label[i]][\"tn\"] = multilabel_confmat[i, 0, 0] + 0.01\n",
        "  cls_report[index2label[i]][\"fp\"] = multilabel_confmat[i, 0, 1] + 0.01\n",
        "  cls_report[index2label[i]][\"fn\"] = multilabel_confmat[i, 1, 0] + 0.01\n",
        "  cls_report[index2label[i]][\"tp\"] = multilabel_confmat[i, 1, 1] + 0.01\n",
        "  cls_report[index2label[i]][\"total\"] = cls_report[index2label[i]][\"tp\"] + cls_report[index2label[i]][\"fn\"]\n",
        "  cls_report[index2label[i]][\"precision\"] = cls_report[index2label[i]][\"tp\"] / (cls_report[index2label[i]][\"fp\"] + cls_report[index2label[i]][\"tp\"])\n",
        "  cls_report[index2label[i]][\"recall\"] = cls_report[index2label[i]][\"tp\"] / (cls_report[index2label[i]][\"fn\"] + cls_report[index2label[i]][\"tp\"])\n",
        "  cls_report[index2label[i]][\"f1\"] = 2 * cls_report[index2label[i]][\"precision\"] * cls_report[index2label[i]][\"recall\"] / (cls_report[index2label[i]][\"precision\"] + cls_report[index2label[i]][\"recall\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gf3Gh2opsON",
        "outputId": "48236a74-6f08-4430-e7dc-31c1fcdd8730"
      },
      "source": [
        "cls_report"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'admiration': {'f1': 0.6660687009342474,\n",
              "  'fn': 129.01,\n",
              "  'fp': 247.01,\n",
              "  'precision': 0.6028905822963891,\n",
              "  'recall': 0.7440379350025793,\n",
              "  'tn': 4676.01,\n",
              "  'total': 504.02,\n",
              "  'tp': 375.01},\n",
              " 'amusement': {'f1': 0.8095842480790341,\n",
              "  'fn': 28.01,\n",
              "  'fp': 83.01,\n",
              "  'precision': 0.7397968779386872,\n",
              "  'recall': 0.8939095523066435,\n",
              "  'tn': 5080.01,\n",
              "  'total': 264.02,\n",
              "  'tp': 236.01},\n",
              " 'anger': {'f1': 0.5059096066565809,\n",
              "  'fn': 91.01,\n",
              "  'fp': 118.01,\n",
              "  'precision': 0.4755577282019376,\n",
              "  'recall': 0.5403999596000404,\n",
              "  'tn': 5111.01,\n",
              "  'total': 198.02,\n",
              "  'tp': 107.01},\n",
              " 'annoyance': {'f1': 0.3688836378306726,\n",
              "  'fn': 192.01,\n",
              "  'fp': 246.01,\n",
              "  'precision': 0.3422544248970643,\n",
              "  'recall': 0.4000062496093994,\n",
              "  'tn': 4861.01,\n",
              "  'total': 320.02,\n",
              "  'tp': 128.01},\n",
              " 'approval': {'f1': 0.3920057596928163,\n",
              "  'fn': 204.01,\n",
              "  'fp': 252.01,\n",
              "  'precision': 0.3684276477369555,\n",
              "  'recall': 0.41880804512563385,\n",
              "  'tn': 4824.01,\n",
              "  'total': 351.02,\n",
              "  'tp': 147.01},\n",
              " 'caring': {'f1': 0.4421133875947235,\n",
              "  'fn': 72.01,\n",
              "  'fp': 87.01,\n",
              "  'precision': 0.420010665244634,\n",
              "  'recall': 0.4666716042067841,\n",
              "  'tn': 5205.01,\n",
              "  'total': 135.02,\n",
              "  'tp': 63.01},\n",
              " 'confusion': {'f1': 0.455336560627017,\n",
              "  'fn': 74.01,\n",
              "  'fp': 115.01,\n",
              "  'precision': 0.40722605916915783,\n",
              "  'recall': 0.5163377336295909,\n",
              "  'tn': 5159.01,\n",
              "  'total': 153.02,\n",
              "  'tp': 79.01},\n",
              " 'curiosity': {'f1': 0.5543145228678068,\n",
              "  'fn': 85.01,\n",
              "  'fp': 235.01,\n",
              "  'precision': 0.45852725680844203,\n",
              "  'recall': 0.7006900922470248,\n",
              "  'tn': 4908.01,\n",
              "  'total': 284.02,\n",
              "  'tp': 199.01},\n",
              " 'desire': {'f1': 0.5066648893628366,\n",
              "  'fn': 45.01,\n",
              "  'fp': 29.01,\n",
              "  'precision': 0.5671441360787824,\n",
              "  'recall': 0.45784148397976393,\n",
              "  'tn': 5315.01,\n",
              "  'total': 83.02,\n",
              "  'tp': 38.01},\n",
              " 'disappointment': {'f1': 0.30347538270583363,\n",
              "  'fn': 107.01,\n",
              "  'fp': 95.01,\n",
              "  'precision': 0.316573154941735,\n",
              "  'recall': 0.2914183551847437,\n",
              "  'tn': 5181.01,\n",
              "  'total': 151.02,\n",
              "  'tp': 44.01},\n",
              " 'disapproval': {'f1': 0.39870997018021526,\n",
              "  'fn': 144.01,\n",
              "  'fp': 227.01,\n",
              "  'precision': 0.35143706073938635,\n",
              "  'recall': 0.4606771028387387,\n",
              "  'tn': 4933.01,\n",
              "  'total': 267.02,\n",
              "  'tp': 123.01},\n",
              " 'disgust': {'f1': 0.4481413873216063,\n",
              "  'fn': 69.01,\n",
              "  'fp': 64.01,\n",
              "  'precision': 0.4576342992713099,\n",
              "  'recall': 0.4390343033653064,\n",
              "  'tn': 5240.01,\n",
              "  'total': 123.02000000000001,\n",
              "  'tp': 54.01},\n",
              " 'embarrassment': {'f1': 0.4918086500655309,\n",
              "  'fn': 22.01,\n",
              "  'fp': 9.01,\n",
              "  'precision': 0.6248959200666112,\n",
              "  'recall': 0.4054565099945975,\n",
              "  'tn': 5381.01,\n",
              "  'total': 37.02,\n",
              "  'tp': 15.01},\n",
              " 'excitement': {'f1': 0.4317300916138125,\n",
              "  'fn': 54.01,\n",
              "  'fp': 75.01,\n",
              "  'precision': 0.39517819706498947,\n",
              "  'recall': 0.47573286740438747,\n",
              "  'tn': 5249.01,\n",
              "  'total': 103.02,\n",
              "  'tp': 49.01},\n",
              " 'fear': {'f1': 0.6666290103931315,\n",
              "  'fn': 19.01,\n",
              "  'fp': 40.01,\n",
              "  'precision': 0.595940214098162,\n",
              "  'recall': 0.7563445270443476,\n",
              "  'tn': 5309.01,\n",
              "  'total': 78.02,\n",
              "  'tp': 59.01},\n",
              " 'gratitude': {'f1': 0.9080391491287623,\n",
              "  'fn': 31.01,\n",
              "  'fp': 34.01,\n",
              "  'precision': 0.9042025801363304,\n",
              "  'recall': 0.9119084142946424,\n",
              "  'tn': 5041.01,\n",
              "  'total': 352.02,\n",
              "  'tp': 321.01},\n",
              " 'grief': {'f1': 0.0033112582781456962,\n",
              "  'fn': 6.01,\n",
              "  'fp': 0.01,\n",
              "  'precision': 0.5,\n",
              "  'recall': 0.0016611295681063125,\n",
              "  'tn': 5421.01,\n",
              "  'total': 6.02,\n",
              "  'tp': 0.01},\n",
              " 'joy': {'f1': 0.6048931996512641,\n",
              "  'fn': 50.01,\n",
              "  'fp': 95.01,\n",
              "  'precision': 0.5388311814386952,\n",
              "  'recall': 0.6894174636691094,\n",
              "  'tn': 5171.01,\n",
              "  'total': 161.02,\n",
              "  'tp': 111.01},\n",
              " 'love': {'f1': 0.7906751414619022,\n",
              "  'fn': 34.01,\n",
              "  'fp': 74.01,\n",
              "  'precision': 0.7337961297748363,\n",
              "  'recall': 0.8571128476598605,\n",
              "  'tn': 5115.01,\n",
              "  'total': 238.01999999999998,\n",
              "  'tp': 204.01},\n",
              " 'nervousness': {'f1': 0.38106565176022833,\n",
              "  'fn': 15.01,\n",
              "  'fp': 11.01,\n",
              "  'precision': 0.42113564668769715,\n",
              "  'recall': 0.34795829713292786,\n",
              "  'tn': 5393.01,\n",
              "  'total': 23.02,\n",
              "  'tp': 8.01},\n",
              " 'neutral': {'f1': 0.6597128461817103,\n",
              "  'fn': 585.01,\n",
              "  'fp': 655.01,\n",
              "  'precision': 0.6472789738398078,\n",
              "  'recall': 0.6726337701872391,\n",
              "  'tn': 2985.01,\n",
              "  'total': 1787.02,\n",
              "  'tp': 1202.01},\n",
              " 'optimism': {'f1': 0.5595793182053672,\n",
              "  'fn': 78.01,\n",
              "  'fp': 92.01,\n",
              "  'precision': 0.53999600039996,\n",
              "  'recall': 0.5806364906999247,\n",
              "  'tn': 5149.01,\n",
              "  'total': 186.02,\n",
              "  'tp': 108.01},\n",
              " 'pride': {'f1': 0.1,\n",
              "  'fn': 16.01,\n",
              "  'fp': 0.01,\n",
              "  'precision': 0.5,\n",
              "  'recall': 0.05,\n",
              "  'tn': 5411.01,\n",
              "  'total': 16.020000000000003,\n",
              "  'tp': 0.01},\n",
              " 'realization': {'f1': 0.22038637519064566,\n",
              "  'fn': 119.01,\n",
              "  'fp': 65.01,\n",
              "  'precision': 0.2857613711272248,\n",
              "  'recall': 0.17935457178320233,\n",
              "  'tn': 5217.01,\n",
              "  'total': 145.02,\n",
              "  'tp': 26.01},\n",
              " 'relief': {'f1': 0.13,\n",
              "  'fn': 11.01,\n",
              "  'fp': 0.01,\n",
              "  'precision': 0.5,\n",
              "  'recall': 0.07,\n",
              "  'tn': 5416.01,\n",
              "  'total': 11.02,\n",
              "  'tp': 0.01},\n",
              " 'remorse': {'f1': 0.6762082853855006,\n",
              "  'fn': 9.01,\n",
              "  'fp': 36.01,\n",
              "  'precision': 0.5662490966032281,\n",
              "  'recall': 0.8391645840771154,\n",
              "  'tn': 5335.01,\n",
              "  'total': 56.019999999999996,\n",
              "  'tp': 47.01},\n",
              " 'sadness': {'f1': 0.5243872698451407,\n",
              "  'fn': 70.01,\n",
              "  'fp': 86.01,\n",
              "  'precision': 0.5,\n",
              "  'recall': 0.5512754775028842,\n",
              "  'tn': 5185.01,\n",
              "  'total': 156.02,\n",
              "  'tp': 86.01},\n",
              " 'surprise': {'f1': 0.5441111601235111,\n",
              "  'fn': 67.01,\n",
              "  'fp': 57.01,\n",
              "  'precision': 0.5648755915127461,\n",
              "  'recall': 0.5248191745851652,\n",
              "  'tn': 5229.01,\n",
              "  'total': 141.02,\n",
              "  'tp': 74.01}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhBDdC0EV-E6"
      },
      "source": [
        "def get_attr_class(cls_report, metric_name):\n",
        "  return [x[metric_name] for x in list(cls_report.values())]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "lBJIra-yKjFC",
        "outputId": "55c8184d-b5d5-469f-88b4-82f0e90bf94f"
      },
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "ax.set_title('Number of instances per class in the test set')\n",
        "metric_name = \"total\"\n",
        "ax.bar(list(label2index.values()), [x[metric_name] for x in list(cls_report.values())])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "ryrGBSzOV4NQ",
        "outputId": "e0a2a646-ae79-4b81-cdc3-c1adcb6697d4"
      },
      "source": [
        "# make two columns\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "ax.set_title('F1 score per class in the test set')\n",
        "metric_name = \"f1\"\n",
        "ax.bar(list(label2index.values()), [x[metric_name] for x in list(cls_report.values())])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0YdQt6pWJnI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}