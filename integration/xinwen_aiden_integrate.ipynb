{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "xinwen_aiden_integrate.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "49281609c9c749088365b50efa00aa72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6e1d6f55b4de474ea00a9c307c23350e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cedaca5c0fed4b7fa8d05623f90c0605",
              "IPY_MODEL_a248d2e9e2d34808a1139fd53e74db6e"
            ]
          }
        },
        "6e1d6f55b4de474ea00a9c307c23350e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cedaca5c0fed4b7fa8d05623f90c0605": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f70531d6e8fb4e859be0ab694f5a0a22",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4720959b828d430f8957ab73dc5db553"
          }
        },
        "a248d2e9e2d34808a1139fd53e74db6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8464c44978014ac8ac38c822bde97860",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170/170 [00:31&lt;00:00,  5.33it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7c9e1d7a73544dea889a19b4f509ad8b"
          }
        },
        "f70531d6e8fb4e859be0ab694f5a0a22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4720959b828d430f8957ab73dc5db553": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8464c44978014ac8ac38c822bde97860": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7c9e1d7a73544dea889a19b4f509ad8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55k8J-h8Uz5K"
      },
      "source": [
        "## Install and import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKUheZwrAjys",
        "outputId": "2e7787fe-551b-4539-ffc2-c5ced1c8fdde"
      },
      "source": [
        "!pip install datasets transformers attrdict"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (1.6.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.5.1)\n",
            "Requirement already satisfied: attrdict in /usr/local/lib/python3.7/dist-packages (2.0.1)\n",
            "Requirement already satisfied: huggingface-hub<0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.0.8)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.7/dist-packages (from datasets) (2021.4.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.11.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (20.9)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from datasets) (3.10.1)\n",
            "Requirement already satisfied: pyarrow>=1.0.0<4.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from attrdict) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.7.4.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuJGaXYXANoX"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertPreTrainedModel, BertModel\n",
        "from transformers import BertTokenizer\n",
        "from typing import Union, Optional\n",
        "\n",
        "import numpy as np\n",
        "from transformers.pipelines import ArgumentHandler\n",
        "from transformers import (\n",
        "    Pipeline,\n",
        "    PreTrainedTokenizer,\n",
        "    ModelCard\n",
        ")\n",
        "from pprint import pprint\n",
        "import os\n",
        "import google.colab as colab\n",
        "import pandas as pd\n",
        "import json\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from attrdict import AttrDict\n",
        "from torch.utils.data import SequentialSampler, DataLoader\n",
        "\n",
        "import os\n",
        "import copy\n",
        "import json\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuuJNk-oQc2P",
        "outputId": "08915180-2bc6-4f11-ee86-cb2d13dabc3d"
      },
      "source": [
        "def mount_google_drive():\n",
        "\t'''\n",
        "\t# Functionality\n",
        "\t\tMount google drive. Since colab does not save files, we want to make it easier to directly access files in google drive.\n",
        "\t# Arguments\n",
        "\t\tNothing\n",
        "\t# Returns\n",
        "\t\tdrive_root: the working directory mounted\n",
        "\t'''\n",
        "\tmount_directory = \"/content/gdrive\"\n",
        "\tdrive = colab.drive\n",
        "\tdrive.mount(mount_directory, force_remount=True)\n",
        "\tdrive_root = mount_directory + \"/\" + list(filter(lambda x: x[0] != '.', os.listdir(mount_directory)))[0]\n",
        "\treturn drive_root\n",
        "\n",
        "ROOT_DIR =  mount_google_drive() + \"/goemotion/\"\n",
        "CHECKPOINT_ROOT = ROOT_DIR + \"xinwen_ckpt/checkpoint-8000\""
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBSowS0E0WT6"
      },
      "source": [
        "## DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0JsAK_30Xje"
      },
      "source": [
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "class InputExample(object):\n",
        "    \"\"\" A single training/test example for simple sequence classification. \"\"\"\n",
        "\n",
        "    def __init__(self, guid, text_a, text_b, label):\n",
        "        self.guid = guid\n",
        "        self.text_a = text_a\n",
        "        self.text_b = text_b\n",
        "        self.label = label\n",
        "\n",
        "    def __repr__(self):\n",
        "        return str(self.to_json_string())\n",
        "\n",
        "    def to_dict(self):\n",
        "        \"\"\"Serializes this instance to a Python dictionary.\"\"\"\n",
        "        output = copy.deepcopy(self.__dict__)\n",
        "        return output\n",
        "\n",
        "    def to_json_string(self):\n",
        "        \"\"\"Serializes this instance to a JSON string.\"\"\"\n",
        "        return json.dumps(self.to_dict(), indent=2, sort_keys=True) + \"\\n\"\n",
        "\n",
        "\n",
        "class InputFeatures(object):\n",
        "    \"\"\"A single set of features of data.\"\"\"\n",
        "\n",
        "    def __init__(self, input_ids, attention_mask, token_type_ids, label):\n",
        "        self.input_ids = input_ids\n",
        "        self.attention_mask = attention_mask\n",
        "        self.token_type_ids = token_type_ids\n",
        "        self.label = label\n",
        "\n",
        "    def __repr__(self):\n",
        "        return str(self.to_json_string())\n",
        "\n",
        "    def to_dict(self):\n",
        "        \"\"\"Serializes this instance to a Python dictionary.\"\"\"\n",
        "        output = copy.deepcopy(self.__dict__)\n",
        "        return output\n",
        "\n",
        "    def to_json_string(self):\n",
        "        \"\"\"Serializes this instance to a JSON string.\"\"\"\n",
        "        return json.dumps(self.to_dict(), indent=2, sort_keys=True) + \"\\n\"\n",
        "\n",
        "\n",
        "def convert_examples_to_features(\n",
        "        args,\n",
        "        examples,\n",
        "        tokenizer,\n",
        "        max_length,\n",
        "):\n",
        "    processor = GoEmotionsProcessor(args)\n",
        "    label_list_len = len(processor.get_labels())\n",
        "\n",
        "    def convert_to_one_hot_label(label):\n",
        "        one_hot_label = [0] * label_list_len\n",
        "        for l in label:\n",
        "            one_hot_label[l] = 1\n",
        "        return one_hot_label\n",
        "\n",
        "    labels = [convert_to_one_hot_label(example.label) for example in examples]\n",
        "\n",
        "    batch_encoding = tokenizer.batch_encode_plus(\n",
        "        [(example.text_a, example.text_b) for example in examples], max_length=max_length, pad_to_max_length=True\n",
        "    )\n",
        "\n",
        "    features = []\n",
        "    for i in range(len(examples)):\n",
        "        inputs = {k: batch_encoding[k][i] for k in batch_encoding}\n",
        "\n",
        "        feature = InputFeatures(**inputs, label=labels[i])\n",
        "        features.append(feature)\n",
        "\n",
        "    for i, example in enumerate(examples[:10]):\n",
        "        logger.info(\"*** Example ***\")\n",
        "        logger.info(\"guid: {}\".format(example.guid))\n",
        "        logger.info(\"sentence: {}\".format(example.text_a))\n",
        "        logger.info(\"tokens: {}\".format(\" \".join([str(x) for x in tokenizer.tokenize(example.text_a)])))\n",
        "        logger.info(\"input_ids: {}\".format(\" \".join([str(x) for x in features[i].input_ids])))\n",
        "        logger.info(\"attention_mask: {}\".format(\" \".join([str(x) for x in features[i].attention_mask])))\n",
        "        logger.info(\"token_type_ids: {}\".format(\" \".join([str(x) for x in features[i].token_type_ids])))\n",
        "        logger.info(\"label: {}\".format(\" \".join([str(x) for x in features[i].label])))\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "class GoEmotionsProcessor(object):\n",
        "    \"\"\"Processor for the GoEmotions data set \"\"\"\n",
        "\n",
        "    def __init__(self, args):\n",
        "        self.args = args\n",
        "\n",
        "    def get_labels(self):\n",
        "        labels = []\n",
        "        with open(os.path.join(self.args.data_dir, self.args.label_file), \"r\", encoding=\"utf-8\") as f:\n",
        "            for line in f:\n",
        "                labels.append(line.rstrip())\n",
        "        return labels\n",
        "    \n",
        "    def obtain_label_text(self):\n",
        "        label_list = self.get_labels()\n",
        "        for i in range(len(label_list)):\n",
        "            if label_list[i] == 'optimism':\n",
        "                label_list[i] = 'optimistic'\n",
        "            elif label_list[i] == 'nervousness':\n",
        "                label_list[i] = 'nervous'\n",
        "        label_text = ' '.join(label_list)\n",
        "        self.label_text = label_text\n",
        "        self.label_length = len(label_list)\n",
        "        return\n",
        "\n",
        "    @classmethod\n",
        "    def _read_file(cls, input_file):\n",
        "        \"\"\"Reads a tab separated value file.\"\"\"\n",
        "        with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
        "            return f.readlines()\n",
        "\n",
        "    def _create_examples(self, lines, set_type):\n",
        "        \"\"\" Creates examples for the train, dev and test sets.\"\"\"\n",
        "        examples = []\n",
        "        for (i, line) in enumerate(lines):\n",
        "            guid = \"%s-%s\" % (set_type, i)\n",
        "            line = line.strip()\n",
        "            items = line.split(\"\\t\")\n",
        "            text_b = items[0]\n",
        "            label = list(map(int, items[1].split(\",\")))\n",
        "            if i % 5000 == 0:\n",
        "                logger.info(line)\n",
        "            examples.append(InputExample(guid=guid, text_a=self.label_text, text_b=text_b, label=label))\n",
        "        return examples\n",
        "\n",
        "    def get_examples(self, mode):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            mode: train, dev, test\n",
        "        \"\"\"\n",
        "        file_to_read = None\n",
        "        if mode == 'train':\n",
        "            file_to_read = self.args.train_file\n",
        "        elif mode == 'dev':\n",
        "            file_to_read = self.args.dev_file\n",
        "        elif mode == 'test':\n",
        "            file_to_read = self.args.test_file\n",
        "        elif mode == 'new':\n",
        "            file_to_read = self.args.new_file\n",
        "\n",
        "        logger.info(\"LOOKING AT {}\".format(os.path.join(self.args.data_dir, file_to_read)))\n",
        "        return self._create_examples(self._read_file(os.path.join(self.args.data_dir,\n",
        "                                                                  file_to_read)), mode)\n",
        "\n",
        "\n",
        "def load_and_cache_examples(args, tokenizer, mode):\n",
        "    processor = GoEmotionsProcessor(args)\n",
        "    processor.obtain_label_text()\n",
        "    # Load data features from cache or dataset file\n",
        "    cached_features_file = os.path.join(\n",
        "        args.data_dir,\n",
        "        \"cached_{}_{}_{}_{}\".format(\n",
        "            str(args.task),\n",
        "            list(filter(None, args.model_name_or_path.split(\"/\"))).pop(),\n",
        "            str(args.max_seq_len),\n",
        "            mode\n",
        "        )\n",
        "    )\n",
        "    if os.path.exists(cached_features_file):\n",
        "        logger.info(\"Loading features from cached file %s\", cached_features_file)\n",
        "        features = torch.load(cached_features_file)\n",
        "        candidate_examples = processor.get_examples(\"new\")\n",
        "        candidate_features = convert_examples_to_features(\n",
        "            args, candidate_examples, tokenizer, max_length=args.max_seq_len+processor.label_length\n",
        "        )\n",
        "    else:\n",
        "        logger.info(\"Creating features from dataset file at %s\", args.data_dir)\n",
        "        if mode == \"train\":\n",
        "            examples = processor.get_examples(\"train\")\n",
        "        elif mode == \"dev\":\n",
        "            examples = processor.get_examples(\"dev\")\n",
        "        elif mode == \"test\":\n",
        "            examples = processor.get_examples(\"test\")\n",
        "        elif mode == \"new\":\n",
        "            examples = processor.get_examples(\"new\")\n",
        "        else:\n",
        "            raise ValueError(\"For mode, only train, dev, test, new is available\")\n",
        "        features = convert_examples_to_features(\n",
        "            args, examples, tokenizer, max_length=args.max_seq_len+processor.label_length\n",
        "        )\n",
        "        candidate_examples = processor.get_examples(\"new\")\n",
        "        candidate_features = convert_examples_to_features(\n",
        "            args, candidate_examples, tokenizer, max_length=args.max_seq_len+processor.label_length\n",
        "        )\n",
        "        logger.info(\"Saving features into cached file %s\", cached_features_file)\n",
        "        torch.save(features, cached_features_file)\n",
        "\n",
        "    # Convert to Tensors and build dataset\n",
        "    all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
        "    all_attention_mask = torch.tensor([f.attention_mask for f in features], dtype=torch.long)\n",
        "    all_token_type_ids = torch.tensor([f.token_type_ids for f in features], dtype=torch.long)\n",
        "    all_labels = torch.tensor([f.label for f in features], dtype=torch.float)\n",
        "    candidate_input_ids = torch.tensor([f.input_ids for f in candidate_features], dtype=torch.long)\n",
        "    candidate_attention_mask = torch.tensor([f.attention_mask for f in candidate_features], dtype=torch.long)\n",
        "    candidate_token_type_ids = torch.tensor([f.token_type_ids for f in candidate_features], dtype=torch.long)\n",
        "\n",
        "    dataset = TensorDataset(all_input_ids, all_attention_mask, all_token_type_ids, all_labels, candidate_input_ids, candidate_attention_mask, candidate_token_type_ids)\n",
        "    return dataset"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5KIaRKJU75a"
      },
      "source": [
        "## Model Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hERifRwsCgvD"
      },
      "source": [
        "class BertForMultiLabelClassification(BertPreTrainedModel):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.num_labels = config.num_labels\n",
        "\n",
        "        self.bert = BertModel(config)\n",
        "        self.pool_classifier = nn.Sequential(\n",
        "            nn.Linear(config.hidden_size, config.hidden_size),\n",
        "            nn.Tanh(),\n",
        "            nn.Dropout(config.hidden_dropout_prob),\n",
        "            nn.Linear(config.hidden_size, 1)\n",
        "        )\n",
        "        # self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        # self.classifier = nn.Linear(config.hidden_size, self.config.num_labels)\n",
        "        self.loss_fct = nn.BCEWithLogitsLoss()\n",
        "\n",
        "        self.init_weights()\n",
        "        self.mixing_rate = 0.92\n",
        "\n",
        "    def forward(\n",
        "            self,\n",
        "            input_ids=None,\n",
        "            attention_mask=None,\n",
        "            token_type_ids=None,\n",
        "            candidate_input_ids=None,\n",
        "            candidate_attention_mask=None,\n",
        "            candidate_token_type_ids=None,\n",
        "            position_ids=None,\n",
        "            head_mask=None,\n",
        "            inputs_embeds=None,\n",
        "            labels=None,\n",
        "    ):\n",
        "        outputs = self.bert(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "        )\n",
        "\n",
        "        if candidate_input_ids is not None and candidate_attention_mask is not None and candidate_token_type_ids is not None:\n",
        "          candidate_outputs = self.bert(\n",
        "              candidate_input_ids,\n",
        "              attention_mask=candidate_attention_mask,\n",
        "              token_type_ids=candidate_token_type_ids,\n",
        "              position_ids=position_ids,\n",
        "              head_mask=head_mask,\n",
        "              inputs_embeds=inputs_embeds\n",
        "          )\n",
        "          temp = self.mixing_rate * outputs[0] + (1 - self.mixing_rate) * candidate_outputs[0]\n",
        "          last_hidden_state = temp[:, 1:self.config.num_labels+1] # only get the states corresponding to labels\n",
        "        else:\n",
        "          last_hidden_state = outputs[0][:, 1:self.config.num_labels+1] # only get the states corresponding to labels\n",
        "\n",
        "        logits = self.pool_classifier(last_hidden_state).squeeze(-1)\n",
        "\n",
        "        # pooled_output = outputs[1]\n",
        "        # pooled_output = self.dropout(pooled_output)\n",
        "        # logits = self.classifier(pooled_output)\n",
        "\n",
        "        outputs = (logits,) + outputs[2:]  # add hidden states and attention if they are here\n",
        "\n",
        "        if labels is not None:\n",
        "            loss = self.loss_fct(logits, labels)\n",
        "            outputs = (loss,) + outputs\n",
        "\n",
        "        return outputs  # (loss), logits, (hidden_states), (attentions)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7BwhC2r_DB4"
      },
      "source": [
        "# Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXP_HKrm_Edg"
      },
      "source": [
        "class MultiLabelTestInferencePipeline(Pipeline):\n",
        "    def __init__(\n",
        "            self,\n",
        "            model: Union[\"PreTrainedModel\", \"TFPreTrainedModel\"],\n",
        "            tokenizer: PreTrainedTokenizer,\n",
        "            modelcard: Optional[ModelCard] = None,\n",
        "            framework: Optional[str] = None,\n",
        "            task: str = \"\",\n",
        "            args_parser: ArgumentHandler = None,\n",
        "            device: int = -1,\n",
        "            binary_output: bool = False,\n",
        "            threshold: float = 0.3,\n",
        "            taxonomy = \"original\"\n",
        "    ):\n",
        "        super().__init__(\n",
        "            model=model,\n",
        "            tokenizer=tokenizer,\n",
        "            modelcard=modelcard,\n",
        "            framework=framework,\n",
        "            args_parser=args_parser,\n",
        "            device=device,\n",
        "            binary_output=binary_output,\n",
        "            task=task\n",
        "        )\n",
        "\n",
        "        self.threshold = threshold\n",
        "\n",
        "        # config_filename = \"{}.json\".format(taxonomy)\n",
        "        # with open(os.path.join(\"config\", config_filename)) as f:\n",
        "        #     args = AttrDict(json.load(f))\n",
        "        orig_dict = {\n",
        "        \"task\": \"goemotions\",\n",
        "        \"data_dir\": ROOT_DIR + \"data/original\",\n",
        "        \"ckpt_dir\": ROOT_DIR + \"ckpt/original\",\n",
        "        \"output_dir\": \"bert-base-cased-goemotions-original\",\n",
        "        \"train_file\": \"train.tsv\",\n",
        "        \"dev_file\": \"dev.tsv\",\n",
        "        \"test_file\": \"test.tsv\",\n",
        "        \"new_file\": \"new.tsv\",\n",
        "        \"label_file\": \"labels.txt\",\n",
        "        \"evaluate_test_during_training\": False,\n",
        "        \"eval_all_checkpoints\": True,\n",
        "        \"save_optimizer\": False,\n",
        "        \"do_lower_case\": False,\n",
        "        \"do_train\": True,\n",
        "        \"do_eval\": True,\n",
        "        \"max_seq_len\": 50,\n",
        "        \"num_train_epochs\": 4,\n",
        "        \"weight_decay\": 0.0,\n",
        "        \"gradient_accumulation_steps\": 1,\n",
        "        \"adam_epsilon\": 1e-8,\n",
        "        \"warmup_proportion\": 0.1,\n",
        "        \"max_steps\": -1,\n",
        "        \"max_grad_norm\": 1.0,\n",
        "        \"no_cuda\": False,\n",
        "        \"model_type\": \"bert\",\n",
        "        \"model_name_or_path\": \"bert-base-cased\",\n",
        "        \"tokenizer_name_or_path\": \"monologg/bert-base-cased-goemotions-original\",\n",
        "        \"seed\": 42,\n",
        "        \"train_batch_size\": 16,\n",
        "        \"eval_batch_size\": 32,\n",
        "        \"logging_steps\": 1000,\n",
        "        \"save_steps\": 1000,\n",
        "        \"learning_rate\": 5e-5,\n",
        "        \"threshold\": 0.3\n",
        "        }\n",
        "        args = AttrDict(orig_dict)\n",
        "\n",
        "        args.output_dir = os.path.join(args.ckpt_dir, args.output_dir)\n",
        "\n",
        "        processor = GoEmotionsProcessor(args)\n",
        "        label_list = processor.get_labels()\n",
        "\n",
        "        args.device = \"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\"\n",
        "        model.to(args.device)\n",
        "\n",
        "        eval_dataset = load_and_cache_examples(args, tokenizer, mode=\"test\") if args.test_file else None\n",
        "        eval_sampler = SequentialSampler(eval_dataset)\n",
        "        self.eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args.eval_batch_size)\n",
        "\n",
        "        self.args = args\n",
        "        self.model = model\n",
        "\n",
        "    def __call__(self, *args, **kwargs):\n",
        "\n",
        "        results = []\n",
        "        ground_truths = []\n",
        "        for batch in tqdm(self.eval_dataloader):\n",
        "            self.model.eval()\n",
        "            for label in batch[3]:\n",
        "                label_text = []\n",
        "                idxs = np.where(label.numpy() == 1.0)[0]\n",
        "                for idx in idxs:\n",
        "                    label_text.append(self.model.config.id2label[idx])\n",
        "                ground_truths.append(label_text)\n",
        "            batch = tuple(t.to(self.args.device) for t in batch)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                inputs = {\n",
        "                    \"input_ids\": batch[0],\n",
        "                    \"attention_mask\": batch[1],\n",
        "                    \"token_type_ids\": batch[2],\n",
        "                    \"labels\": batch[3],\n",
        "                    \"candidate_input_ids\": batch[4],\n",
        "                    \"candidate_attention_mask\": batch[5],\n",
        "                    \"candidate_token_type_ids\": batch[6]\n",
        "                }\n",
        "                outputs = self.model(**inputs)[1].detach().cpu()\n",
        "\n",
        "            scores = 1 / (1 + np.exp(-outputs))  # Sigmoid\n",
        "            for item in scores:\n",
        "                labels = []\n",
        "                scores = []\n",
        "                for idx, s in enumerate(item):\n",
        "                    if s > self.threshold:\n",
        "                        labels.append(self.model.config.id2label[idx])\n",
        "                        scores.append(float(s))\n",
        "                results.append({\"labels\": labels, \"scores\": scores})\n",
        "\n",
        "        return results, ground_truths"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMbWJfoseqti"
      },
      "source": [
        "# Inference On Testset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137,
          "referenced_widgets": [
            "49281609c9c749088365b50efa00aa72",
            "6e1d6f55b4de474ea00a9c307c23350e",
            "cedaca5c0fed4b7fa8d05623f90c0605",
            "a248d2e9e2d34808a1139fd53e74db6e",
            "f70531d6e8fb4e859be0ab694f5a0a22",
            "4720959b828d430f8957ab73dc5db553",
            "8464c44978014ac8ac38c822bde97860",
            "7c9e1d7a73544dea889a19b4f509ad8b"
          ]
        },
        "id": "l6vbHOge6WfT",
        "outputId": "d9b12766-97e4-4821-b3cb-7505d7afba2d"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(CHECKPOINT_ROOT)\n",
        "model = BertForMultiLabelClassification.from_pretrained(CHECKPOINT_ROOT)\n",
        "\n",
        "goemotions = MultiLabelTestInferencePipeline(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    threshold=0.3\n",
        ")\n",
        "\n",
        "raw_predictions, ground_truths = goemotions()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "49281609c9c749088365b50efa00aa72",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=170.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFT5SB3x6W5I"
      },
      "source": [
        "# Load training sentences\n",
        "train_df = pd.read_csv(ROOT_DIR + \"data/original/train.tsv\", sep='\\t', header=None, names=[\"sentence\", \"label\", \"encoding\"])\n",
        "train_sentences = train_df.sentence.tolist()\n",
        "\n",
        "# Load labels and build dicts\n",
        "with open(ROOT_DIR + \"data/original/labels.txt\", \"r\") as f:\n",
        "  labels = f.read().splitlines()\n",
        "label2index = {v: k for k, v in enumerate(labels)}\n",
        "index2label = {k: v for k, v in enumerate(labels)}\n",
        "\n",
        "\n",
        "# Load test set, get test sents and ground truths\n",
        "test_df = pd.read_csv(ROOT_DIR + \"data/original/test.tsv\", sep='\\t', header=None, names=[\"sentence\", \"label\", \"encoding\"])\n",
        "test_sentences = test_df.sentence.tolist()\n",
        "\n",
        "\n",
        "# Create ground truth label format\n",
        "ground_truths = []\n",
        "for x in test_df.label.tolist():\n",
        "  single_idxs = x.split(\",\")\n",
        "  single_labels = []\n",
        "  for label in single_idxs:\n",
        "    single_labels.append(index2label[int(label)])\n",
        "  ground_truths.append(single_labels)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRlMrWFQCkd-"
      },
      "source": [
        "predictions = [x[\"labels\"] for x in raw_predictions]"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IjZ0zw6CnKE"
      },
      "source": [
        "assert len(ground_truths) == len(predictions)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xy0algSxCpBc",
        "outputId": "12ee248f-b678-4b93-e8e3-f0036ec6cb22"
      },
      "source": [
        "num_em = 0\n",
        "for i, (pred, truth) in enumerate(zip(predictions, ground_truths)):\n",
        "  if pred == truth:\n",
        "    num_em += 1\n",
        "print(num_em / len(predictions))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.43191450156624284\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_w0YTw2uCqdz"
      },
      "source": [
        "def convert_onehot(inputs):\n",
        "  final_arr = np.zeros((len(inputs), len(label2index.keys())))\n",
        "  for i, labels in enumerate(inputs):\n",
        "    for label in labels:\n",
        "      final_arr[i, label2index[label]] = 1\n",
        "  return final_arr"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FR0SWZ4fCrs7"
      },
      "source": [
        "onehot_truths = convert_onehot(ground_truths)\n",
        "onehot_preds = convert_onehot(predictions)\n",
        "multilabel_confmat = multilabel_confusion_matrix(onehot_truths, onehot_preds)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bq15KATPCs2d"
      },
      "source": [
        "cls_report = {}\n",
        "for i in range(multilabel_confmat.shape[0]):\n",
        "  cls_report[index2label[i]] = {}\n",
        "  cls_report[index2label[i]][\"tn\"] = multilabel_confmat[i, 0, 0] + 1\n",
        "  cls_report[index2label[i]][\"fp\"] = multilabel_confmat[i, 0, 1] + 1\n",
        "  cls_report[index2label[i]][\"fn\"] = multilabel_confmat[i, 1, 0] + 1\n",
        "  cls_report[index2label[i]][\"tp\"] = multilabel_confmat[i, 1, 1] + 1\n",
        "  cls_report[index2label[i]][\"total\"] = cls_report[index2label[i]][\"tp\"] + cls_report[index2label[i]][\"fn\"]\n",
        "  cls_report[index2label[i]][\"precision\"] = cls_report[index2label[i]][\"tp\"] / (cls_report[index2label[i]][\"fp\"] + cls_report[index2label[i]][\"tp\"])\n",
        "  cls_report[index2label[i]][\"recall\"] = cls_report[index2label[i]][\"tp\"] / (cls_report[index2label[i]][\"fn\"] + cls_report[index2label[i]][\"tp\"])\n",
        "  cls_report[index2label[i]][\"f1\"] = 2 * cls_report[index2label[i]][\"precision\"] * cls_report[index2label[i]][\"recall\"] / (cls_report[index2label[i]][\"precision\"] + cls_report[index2label[i]][\"recall\"])"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHOwcyGgCu3A",
        "outputId": "5c9c6e7c-7b9c-4513-a002-3b34fa71bafd"
      },
      "source": [
        "cls_report"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'admiration': {'f1': 0.6834264432029795,\n",
              "  'fn': 139,\n",
              "  'fp': 201,\n",
              "  'precision': 0.6461267605633803,\n",
              "  'recall': 0.7252964426877471,\n",
              "  'tn': 4724,\n",
              "  'total': 506,\n",
              "  'tp': 367},\n",
              " 'amusement': {'f1': 0.82,\n",
              "  'fn': 20,\n",
              "  'fp': 88,\n",
              "  'precision': 0.7365269461077845,\n",
              "  'recall': 0.924812030075188,\n",
              "  'tn': 5077,\n",
              "  'total': 266,\n",
              "  'tp': 246},\n",
              " 'anger': {'f1': 0.5346062052505968,\n",
              "  'fn': 88,\n",
              "  'fp': 107,\n",
              "  'precision': 0.5114155251141552,\n",
              "  'recall': 0.56,\n",
              "  'tn': 5124,\n",
              "  'total': 200,\n",
              "  'tp': 112},\n",
              " 'annoyance': {'f1': 0.38255033557046986,\n",
              "  'fn': 208,\n",
              "  'fp': 160,\n",
              "  'precision': 0.41605839416058393,\n",
              "  'recall': 0.35403726708074534,\n",
              "  'tn': 4949,\n",
              "  'total': 322,\n",
              "  'tp': 114},\n",
              " 'approval': {'f1': 0.3827493261455525,\n",
              "  'fn': 211,\n",
              "  'fp': 247,\n",
              "  'precision': 0.36503856041131105,\n",
              "  'recall': 0.40226628895184136,\n",
              "  'tn': 4831,\n",
              "  'total': 353,\n",
              "  'tp': 142},\n",
              " 'caring': {'f1': 0.42320819112627983,\n",
              "  'fn': 75,\n",
              "  'fp': 94,\n",
              "  'precision': 0.3974358974358974,\n",
              "  'recall': 0.45255474452554745,\n",
              "  'tn': 5200,\n",
              "  'total': 137,\n",
              "  'tp': 62},\n",
              " 'confusion': {'f1': 0.484149855907781,\n",
              "  'fn': 71,\n",
              "  'fp': 108,\n",
              "  'precision': 0.4375,\n",
              "  'recall': 0.5419354838709678,\n",
              "  'tn': 5168,\n",
              "  'total': 155,\n",
              "  'tp': 84},\n",
              " 'curiosity': {'f1': 0.5692307692307692,\n",
              "  'fn': 64,\n",
              "  'fp': 272,\n",
              "  'precision': 0.4493927125506073,\n",
              "  'recall': 0.7762237762237763,\n",
              "  'tn': 4873,\n",
              "  'total': 286,\n",
              "  'tp': 222},\n",
              " 'desire': {'f1': 0.5034013605442176,\n",
              "  'fn': 48,\n",
              "  'fp': 25,\n",
              "  'precision': 0.5967741935483871,\n",
              "  'recall': 0.43529411764705883,\n",
              "  'tn': 5321,\n",
              "  'total': 85,\n",
              "  'tp': 37},\n",
              " 'disappointment': {'f1': 0.2965779467680608,\n",
              "  'fn': 114,\n",
              "  'fp': 71,\n",
              "  'precision': 0.35454545454545455,\n",
              "  'recall': 0.2549019607843137,\n",
              "  'tn': 5207,\n",
              "  'total': 153,\n",
              "  'tp': 39},\n",
              " 'disapproval': {'f1': 0.4119601328903654,\n",
              "  'fn': 145,\n",
              "  'fp': 209,\n",
              "  'precision': 0.37237237237237236,\n",
              "  'recall': 0.46096654275092935,\n",
              "  'tn': 4953,\n",
              "  'total': 269,\n",
              "  'tp': 124},\n",
              " 'disgust': {'f1': 0.47107438016528924,\n",
              "  'fn': 68,\n",
              "  'fp': 60,\n",
              "  'precision': 0.48717948717948717,\n",
              "  'recall': 0.456,\n",
              "  'tn': 5246,\n",
              "  'total': 125,\n",
              "  'tp': 57},\n",
              " 'embarrassment': {'f1': 0.4657534246575343,\n",
              "  'fn': 22,\n",
              "  'fp': 17,\n",
              "  'precision': 0.5,\n",
              "  'recall': 0.4358974358974359,\n",
              "  'tn': 5375,\n",
              "  'total': 39,\n",
              "  'tp': 17},\n",
              " 'excitement': {'f1': 0.44670050761421326,\n",
              "  'fn': 61,\n",
              "  'fp': 48,\n",
              "  'precision': 0.4782608695652174,\n",
              "  'recall': 0.41904761904761906,\n",
              "  'tn': 5278,\n",
              "  'total': 105,\n",
              "  'tp': 44},\n",
              " 'fear': {'f1': 0.7065868263473054,\n",
              "  'fn': 21,\n",
              "  'fp': 28,\n",
              "  'precision': 0.6781609195402298,\n",
              "  'recall': 0.7375,\n",
              "  'tn': 5323,\n",
              "  'total': 80,\n",
              "  'tp': 59},\n",
              " 'gratitude': {'f1': 0.9041095890410958,\n",
              "  'fn': 24,\n",
              "  'fp': 46,\n",
              "  'precision': 0.8776595744680851,\n",
              "  'recall': 0.9322033898305084,\n",
              "  'tn': 5031,\n",
              "  'total': 354,\n",
              "  'tp': 330},\n",
              " 'grief': {'f1': 0.35714285714285715,\n",
              "  'fn': 3,\n",
              "  'fp': 15,\n",
              "  'precision': 0.25,\n",
              "  'recall': 0.625,\n",
              "  'tn': 5408,\n",
              "  'total': 8,\n",
              "  'tp': 5},\n",
              " 'joy': {'f1': 0.601123595505618,\n",
              "  'fn': 56,\n",
              "  'fp': 86,\n",
              "  'precision': 0.5544041450777202,\n",
              "  'recall': 0.656441717791411,\n",
              "  'tn': 5182,\n",
              "  'total': 163,\n",
              "  'tp': 107},\n",
              " 'love': {'f1': 0.7977315689981096,\n",
              "  'fn': 29,\n",
              "  'fp': 78,\n",
              "  'precision': 0.7301038062283737,\n",
              "  'recall': 0.8791666666666667,\n",
              "  'tn': 5113,\n",
              "  'total': 240,\n",
              "  'tp': 211},\n",
              " 'nervousness': {'f1': 0.38095238095238104,\n",
              "  'fn': 17,\n",
              "  'fp': 9,\n",
              "  'precision': 0.47058823529411764,\n",
              "  'recall': 0.32,\n",
              "  'tn': 5397,\n",
              "  'total': 25,\n",
              "  'tp': 8},\n",
              " 'neutral': {'f1': 0.6790626591951096,\n",
              "  'fn': 456,\n",
              "  'fp': 804,\n",
              "  'precision': 0.6237716424894713,\n",
              "  'recall': 0.7451089994410285,\n",
              "  'tn': 2838,\n",
              "  'total': 1789,\n",
              "  'tp': 1333},\n",
              " 'optimism': {'f1': 0.5754189944134078,\n",
              "  'fn': 85,\n",
              "  'fp': 67,\n",
              "  'precision': 0.6058823529411764,\n",
              "  'recall': 0.5478723404255319,\n",
              "  'tn': 5176,\n",
              "  'total': 188,\n",
              "  'tp': 103},\n",
              " 'pride': {'f1': 0.4827586206896552,\n",
              "  'fn': 11,\n",
              "  'fp': 4,\n",
              "  'precision': 0.6363636363636364,\n",
              "  'recall': 0.3888888888888889,\n",
              "  'tn': 5409,\n",
              "  'total': 18,\n",
              "  'tp': 7},\n",
              " 'realization': {'f1': 0.2627118644067797,\n",
              "  'fn': 116,\n",
              "  'fp': 58,\n",
              "  'precision': 0.34831460674157305,\n",
              "  'recall': 0.2108843537414966,\n",
              "  'tn': 5226,\n",
              "  'total': 147,\n",
              "  'tp': 31},\n",
              " 'relief': {'f1': 0.42105263157894735,\n",
              "  'fn': 9,\n",
              "  'fp': 2,\n",
              "  'precision': 0.6666666666666666,\n",
              "  'recall': 0.3076923076923077,\n",
              "  'tn': 5416,\n",
              "  'total': 13,\n",
              "  'tp': 4},\n",
              " 'remorse': {'f1': 0.6887417218543046,\n",
              "  'fn': 6,\n",
              "  'fp': 41,\n",
              "  'precision': 0.5591397849462365,\n",
              "  'recall': 0.896551724137931,\n",
              "  'tn': 5332,\n",
              "  'total': 58,\n",
              "  'tp': 52},\n",
              " 'sadness': {'f1': 0.5405405405405406,\n",
              "  'fn': 68,\n",
              "  'fp': 85,\n",
              "  'precision': 0.5142857142857142,\n",
              "  'recall': 0.569620253164557,\n",
              "  'tn': 5188,\n",
              "  'total': 158,\n",
              "  'tp': 90},\n",
              " 'surprise': {'f1': 0.5303030303030303,\n",
              "  'fn': 73,\n",
              "  'fp': 51,\n",
              "  'precision': 0.5785123966942148,\n",
              "  'recall': 0.48951048951048953,\n",
              "  'tn': 5237,\n",
              "  'total': 143,\n",
              "  'tp': 70}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6O0TvsICwBS"
      },
      "source": [
        "def get_attr_class(cls_report, metric_name):\n",
        "  return [x[metric_name] for x in list(cls_report.values())]"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "la9vYpCjCzq7",
        "outputId": "4c325509-93d3-4674-ef5f-85b053f78eb3"
      },
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "ax.set_title('Number of instances per class in the test set')\n",
        "metric_name = \"total\"\n",
        "ax.bar(list(label2index.values()), [x[metric_name] for x in list(cls_report.values())])\n",
        "plt.show()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "Oqiw4J8KC0pv",
        "outputId": "d930260a-2213-44b5-c00d-e0d188ef62a0"
      },
      "source": [
        "# make two columns\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "ax.set_title('F1 score per class in the test set')\n",
        "metric_name = \"f1\"\n",
        "ax.bar(list(label2index.values()), [x[metric_name] for x in list(cls_report.values())])\n",
        "plt.show()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lKiRMqfC4qD",
        "outputId": "ef7e9a6e-7ab3-4c60-e2c6-4f0cbb350d7b"
      },
      "source": [
        "sum([x[metric_name] for x in list(cls_report.values())]) / len([x[metric_name] for x in list(cls_report.values())])"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5287009200015446"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJDmBv1_C65Q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}